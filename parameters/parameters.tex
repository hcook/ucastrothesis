\chapter{Context-Dependent Environments: \\ A Parameterization Paradigm for Hardware Generators}
\label{c.parameters}

As Moore's law fails, increasing demand for computational efficiency is no longer being matched by gains from process scaling. 
Instead, chip designers are improving efficiency by combining special-purpose accelerators with general-purpose processors in increasingly heterogeneous systems-on-chip.
In this new world of energy-efficient, heterogeneous, application-specific designs, it will be essential to both improve the productivity of hardware designers as well as enable extensive design-space exploration~\cite{shacham-micro10}.

Since it is not possible to build custom chips from scratch for every application,
we need hardware design tools that allow us to capture decisions made
during the process of designing one chip, yet easily make them differently when tackling a new target.
Creating parameterized hardware generators, rather than individual design instances, 
not only allows for application-specific customization of the final hardware,
it also gives designers the capability to preserve knowledge related to performance and energy trade-offs from previous design iterations.
By parameterizing aspects of the design, we can scale it from test chip sizes to final product without rewriting any modules, amortizing verification costs and increasing the validation confidence over time without rewriting code.
This templated, meta-programming approach is integral to our agile approach to hardware design.

The most salient feature of a hardware generator or template, as
compared to a single design instance, is that certain features of the design are
left under the control of the user deploying the generator within their chip.
We term these features the {\em parameters} of the generator.
{\em Parameterization} is the process by which a generator supplies values for each parameter,
i.e. binds the name of the parameter to a particular value,
before using that evaluation to elaborate details of the particular design instance at hand.
A {\em parameterization paradigm} codifies a particular way of expressing parameters and provides tools to support their application within generators,
as well as mechanisms to constrain their valuations.

The parameters and their constraints become the interface through which the generator author and the system architect communicate.
Constrained parameters serve as boundaries that define the space of designs which it is possible for the architect to explore.
By searching over the top-level parameters exposed by a set of such generators, System-on-Chip (SoC) chip architects can explore tradeoffs between performance, area, and energy efficiency.
By recording the outcomes of these explorations, these designers can build up a map of how to customize pieces of their design for a particular application's requirements.

Parameterization is clearly a first-order concern in the creation of tools based around specialized hardware generation.
In order to use generators productively, we need to understand how the choice of parameterization paradigm affects the design process.
We claim that the mechanism by which generator-based designs are parameterized can greatly influence three metrics of design robustness: reusability, composability, and modifiability.
We define these three metrics as follows:
\begin{description}
\item[Reusing] generators means that they can be instantiated as components of different broader hardware contexts with no internal source code changes, only differing parameterizations. Reusability amortizes verification overhead by reducing the number of lines of code used to create larger design instances.
\item[Composing] generators requires mechanisms to specify cross-generator parameter constraints and dependencies. Composability is mandatory to build up larger SoC designs consisting of multiple generators.
\item[Modifying] a generator (by adding a new parameters to it) should not cause a cascade of changes throughout any nested modules which instantiate that generator's output. Modifiability is predicated on \emph{modularity} in the code base, and mitigates technical debt that would encumber changing a generator's capabilities.
\end{description}

This chapter first provides a background discussion of how the concepts of parameterization and meta-programming are intertwined, as well as how software languages have addressed parameterization in the past.
We then provide a taxonomy of extant parameterization paradigms found in previous hardware description languages, and evaluate them in terms of the above metrics.
To correct for their deficiencies, we introduce \emph{context-dependent environments}~(CDEs), a new parameterization paradigm.
In the CDE paradigm, a key-value dictionary containing parameter bindings is passed through a hardware module hierarchy, and the value returned for each parameter identifier can depend on other parameter values at that query's origin within the design.
As we will see in this chapter,
the dynamic nature of a CDE's scoping, coupled with its context-specific knowledge, 
serves to support generator reusability and composition, while also improving a generator's robustness to any external module hierarchy modifications.

We provide both a case study and a formal analysis of design robustness with respect to each of the parameterization paradigms in our taxonomy, and prove that CDEs are the most robust option.
We then provide examples of how our open-source Scala implementation of CDEs is used in various sub-components of our RocketChip SoC generator.

As we will see later in this thesis, even a design choice as complicated and pervasive as a multi-level cache coherence protocol can be made a tunable design parameter when properly factored out from the rest of the design. 
By providing support for generating a family of protocols rather than one single protocol, my thesis has enabled us to iterate on protocol design as we scale up the size of the memory hierarchy across chip iterations.

\section{Background}
\label{sec:rel}

%Given a set of top-level configurations that supply value bindings for individual parameters, a generator can construct a vast number of different designs from a single piece of templated source code.
%Hardware generators are an increasingly popular paradigm; examples include Stanford's FPU generator~\cite{fpu}, Lawrence Berkeley National Lab's OpenSoC~\cite{opensoc}, and UC Berkeley's Rocket Chip Generator~\cite{rocket}.
%Bluespec provides AzureIP Libraries~\cite{azure} to give designers reusable components for use in custom generators. 
%Support for parameterization is a critical feature of the language in which the generator is written.

To provide context for our study of the applicability of various parameterization paradigms to hardware generation,
as well as to motivate the value of our new CDE paradigm,
we will first review two concepts at the heart of parameterization:
\emph{meta-programming} and \emph{name binding}.
Meta-programming allows us to create parameterized hardware templates, into which values can be injected to make concrete design instances.
Name binding is the process by which parameter identifiers are associated with particular values.

\subsection{Meta-programming}

When we talk about creating libraries of hardware generators instead of design instances,
the underlying concept that our design tools need to support is meta-programming of hardware descriptions.
A meta-program is a program that generates or manipulates program code~\cite{templates}.
Specifically in the case of this thesis, Chisel~\cite{chisel} is a meta-programming language (that is itself embedded in a host languagage, Scala).
Using Chisel, we can describe parameterized templates for particular hardware modules as Scala classes.
Executing a Scala program that instantiates particular instances of these classes allows the Chisel compiler
to elaborate a concrete design instance in Verilog or some other target language.
Because Chisel is embedded in Scala, we can use the full capabilities of this modern software language to implement our generators.
This chapter will make the case that one of the most essential capabilities that this embedding has put at our disposal
is the ability to use Scala to parameterize our hardware descriptions,
be it through built-in language capabilities or through parameterization frameworks written in the host language.

Traditional hardware description languages have lacked the language features to support parameterization of configurable designs.
Section \ref{sec:tax} will discuss how specific existing parameterization paradigms in Verilog, VHDL, SystemVerilog, and Bluespec SystemVerilog limit design modifiability and customizability.
However, because the outputs of our generators will be fully elaborated designs with parameter values  automatically embedded in them,
we can free generator authors from the constraints of the backend language with respect to choice of parameterization paradigm.
This approach also allows us to supply parameter bindings from external tools at hardware generation time,
which is a critical features for design space exploration~\cite{shacham2011chip}.
It is important to note that there are several different times during the hardware elaboration process where
we might decide to supply parameter values, and in particular, this chapter will discuss tradeoffs between
binding parameters to values at generator compile-time as opposed to generator run-time.

How parameters are expressed and referenced within and among generators is another important design question.
From the perspective of the author of a hardware generator, it is impossible to know the full context in which the components created by their generator will be instantiated.
The goal of the author of a hardware generator is to expose as many parameters as they possibly can to the user (e.g., an SoC architect)
while also recording any constraints the internals of the design put on those parameters' values.
Our parameterization paradigm must also accept constraints that are imposed by parent modules on their children, in the service of interoperability,
or by completely external tools, in the service of design space exploration.
Again, we are aided by the expressionality of the host language and the ability to connect with outside tools at hardware generation time.
Finally, while the parameters themselves are often merely instances of simple numeric or boolean types
depending on the nature of the meta-programming language,
we can also consider utilizing parameters that are bound to functions, user-defined objects, or other parameters.
As we will see, exploiting a host language's capability to use more complicated types in the parameterization framework
is an essential requirement for using it to support customizable cache coherence protocols.

Given the limitations of extant HDLs, adopting new ones with first class support for meta-programming (and thereby parameterization)
is critical to our hardware design methodology.
Chapter 3 of~\cite{shacham2011chip} provides additional discussion of the 
parameterization advantages related to meta-programming
in the context of Genesis2, a next-generation HDL embedded in Perl.
We include a comparison with Genesis2's Perl-based dynamic parameterization paradigm in Section \ref{sec:env}.

\subsection{Name Binding and Scoping}

The opportunity presented by embedding Chisel in Scala inspired us to examine parameterization solutions that have been investigated in software contexts.
Fundamentally, parameterization is a name binding problem, in which a data or code entity must be bound to an identifying name.
In our case, generators express the hardware they elaborate in terms of the parameters' identifiers,
while the framework is in charge of supplying the matching data as the hardware is generated.
What data is supplied for a particular name depends on the scoping of the identifier, which might be handled \emph{lexically} or \emph{dynamically}.
Lisp languages were the first to explore tradeoffs between dynamic scoping and lexical scoping \cite{gordon}.

With lexical scoping, in order to bind a name to an entity, we first search within the local function, then within the scope in which this function was defined, and so on.
``Lexical'' in this case refers to the text of the source code itself.
Lexical scoping provides referential transparency, which is a boon for both the programmer and compiler.
By analyzing the source code, it is possible to determine at compile time whether or not a particular binding is within scope.
Unfortunately, bindings needed by deeply nested components must be explicitly threaded throughout the class or function hierarchy.

With dynamic scoping, we again search first in the local function, but then search the function that called this function, and so on up the call stack of the running program.
``Dynamic'' in this case refers to the fact that the call stack can be different every time a given function is called, and so the binding created for the variable can thereby differ as well.
Dynamic binding is useful as a substitute for globally-scoped variables, and is excellent for deep customization of nested subsystems.
In cases where the necessary bindings may radically change from program instance to program instance, dynamic binding allows us to only specify those bindings that we know the current instance will use.
Unfortunately, in some cases programmer errors that could have been caught at compile time in a lexically-scoped system become runtime errors in a dynamically-scoped system.

While lexical binding is now the norm for most programming languages, many mechanisms have been developed to allow programmers to explicitly tie in dynamic binding benefits where they are useful.
These include special binding forms in most Lisp variants
(e.g., \code{fluid-let} in Scheme \cite{steele} and \code{parameterize} in Racket \cite{flatt2013racket}),
implicit parameters \cite{lewis2000implicit}, and the Reader monad in Haskell \cite{jones1995functional}.
While these approaches all focus on re-enabling the parameterization flexibility of dynamic binding in a more controlled manner, 
the context-dependent environments we propose here are actually a strictly more powerful mechanism than traditional dynamic binding. 
In general, taking advantage of later-binding solutions enables both more concise uniquification of elements of nested, heterogeneous systems~\cite{shacham2011chip},
and also allows us to deal with modifications to the hierarchy of generated modules more robustly.
The following taxonomy illustrates how selectively deploying our dynamic scoping solution is the best fit for hardware generation
by contrasting it with other lexically- and dynamically-scoped solutions.

\section{Taxonomy of Parameterization Paradigms}
\label{sec:tax}

Before introducing context-dependent environments, we first define and contrast three existing parameterization paradigms: argument lists, structs, and dynamic environments.
We examine how these paradigms could be or have been used in hardware description languages.
We then  evaluate them in terms of a simple case study
in which we describe making modifications to a hierarchical hardware generator that is composed from multiple sub-generators.
The three paradigms we contrast in this section are:

\begin{description}
\item[Argument Lists.] The default lexical binding approach wherein all parameters are explicitly passed to the constructor function of each hardware module class.
\item[Structs.] A more sophisticated lexical binding approach wherein user-defined datatypes are used to abstract away specific parameter binding sites.
\item[Environments.] A dynamic binding approach wherein an associative array of key-value pairs is used to supply parameter values at runtime.
\end{description}

We do not consider some other simple alternative parameterization solutions, such as a flat namespace of global constants, because such implementations lack composability and reuseability.
First, without a mechanism to manage namespace collisions between different third-party generators, composing generators without having to modify their internals becomes impossible.
Second, without a mechanism that allows designers to override parameter values within certain subsets of the module hierarchy, creating heterogeneous systems where the same generator
produces differently parameterized output becomes impossible.
For these reasons we only contrast the aforementioned three paradigms, as they support both design goals in their own ways.

%TODOEach scheme preserves module modularity and reusability by expressing all parameters at the top level and only requesting necessary parameters. We evaluate each paradigm's robustness by adding parameters/modules and counting the number of top-level (TLCs), non-local (NLCs), or local (LCs) source code changes cascading from this initial modification.

We can evaluate the robustness of these parameterization paradigms by adding new parameters or inserting additional modules, and then examining the source code changes required to bring the new parameter binding into scope. 
We differentiate three types of source code changes.

\begin{description}
\item[Local changes (LCs)] are the initial insertion or appending of a module instantiation with a new parameter. 
\item[Top-level changes (TLCs)] are new parameter bindings performed at the root of the module hierarchy. 
\item[Non-local changes (NLCs)] are any additional changes required to pass a top-level parameter value (bound by a TLC) to the scope of a lower-level module instantiation (created by an LC). 
\end{description}

LCs and TLCs are simply inherent to instantiating a new parameterized module or adding a new parameter to an existing module.
The module using the parameter must be instantiated somewhere in the hierarchy (LC), and the parameter must be bound to a value
somewhere in that instantiation's scope (TLC).
In some cases, additional LCs are needed to resolve conflicting parameter names at the location where the module is instantiated.

In contrast, NLCs only serve to bring a new parameter binding into scope for the new module instantiation,
or alternatively to correct an inter-module parameter reference that has been outdated by a module insertion.
We view being forced to manually make NLCs within our generators' source code as representative of
the brittleness of a particular parameterization paradigm in the face of changes to child generator interfaces
or module hierarchy depth.
In this way, NLCs are a form of technical debt imposed by the choice of parameterization framework on a hardware generator library.
According to our robustness metric, an ideal parameterization paradigm would eliminate all NLCs,
while simultaneously minimizing the number of LCs and TLCs needed to implement any given design modification.
In general, NLCs are the cost of deploying a paradigm dependent on lexical binding rather than dynamic binding.

%To maximize design modularity and reusability by first binding all parameter names at the top level of the module hierarchy and then requesting necessary parameter values within each module. 
%While default values could be supplied locally, any parameters used in inter-generator design space exploration must be exposed at the top level of each generator.

The following sections use examples written in Verilog-like pseudo-HDL code which elides non-parameter-related expressions.
Figure~\ref{fig:block} displays the block diagram organization of a set of nested hardware modules that we will use in our robustness case study.
We take a Tile generator that is hierarchically composed of Core, Cache, and FPU generators, and investigate how making modifications to the parameters
of the leaf generators impacts the rest of the design, as expressed in our pseudo-HDL.
Figure~\ref{fig:phdl} outlines the syntax for object declaration and instantiation in our pseudo-HDL.
In this pseudo-HDL, we assume every hardware module can be made into a templated hardware generator through the use of the additional \code{\#()} constructor parameter list.
Fields of that list (or fields of objects within the list) are the parameters of the generator/module in question.

\begin{figure}
\centering
\epsfig{file=parameters/figures/tile.pdf, width=2.7in}
\caption{Organization of nested modules used in our running example.
A Tile contains one Core and multiple Caches.
A Core may or may not contain an FPU, which may or may not be parameterized.}
\label{fig:block}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
struct S {f:Bool,g:Int}          // struct declaration
module A #(p1,p2,p3,p4,p5)(...): ... 
   // module declaration: parameters use 1st argument list #(p1,...)
   // other RTL constructs like IOs use 2nd argument list (elided)
module B #()(...):
  a = new S(true, 1)             // struct instantiation
  b = a.f                        // struct access
  myA = new A #(a,b,c,d,e)(...)  // module instantiation
\end{phdl} 
\caption{Syntax for object declaration and instantiation in our HDL pseudocode.}
\label{fig:phdl}
\end{figure}

\subsection{Argument List Parameterization}

\begin{figure}
\centering
\begin{phdl}
module Top#()():
  hasFpu = true  // Whether our core should instantiate an FPU
  icSize = 64    // Size of the instruction cache's blocks
  dcSize = 64    // Size of the data cache's blocks
  myTile = new Tile #(hasFpu, icSize, dcSize)(...)
module Tile #(hasFpu, icSize, dcSize)(...):
  myCore = new Core  #(hasFpu)(...)
  icache = new Cache #(icSize)(...)
  dcache = new Cache #(dcSize)(...)
  assert (icSize == dcSize)         // The tile is multiplexing a single port
module Cache #(blockSize)(...): ... // icSize/dcSize each renamed blockSize
module Core #(hasFpu)(...):
  if(hasFpu) myFpu = new FPU()(...) ...
module FPU #()(...): ...
\end{phdl} 
\caption{An example module hierarchy containing a tile with a processor core and two caches, parameterized through constructor arguments.}
\label{fig:arglist}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
module Top #()():
  hasFpu = true  // Whether our core should instantiate an FPU
  (*@\textcolor[rgb]{1,0,0}{fpuLat = 6}@*)     // Latency of FPU                               // TLC
  icSize = 64    // Size of the instruction cache's blocks
  dcSize = 64    // Size of the data cache's blocks
  myTile = new Tile #(hasFpu, icSize, dcSize,(*@\textcolor[rgb]{1,0,0}{fpuLat}@*))(...)        // NLC
module Tile #(hasFpu, icSize, dcSize,(*@\textcolor[rgb]{1,0,0}{fpuLat}@*))(...):               // NLC
  myCore = new Core  #(hasFpu, (*@\textcolor[rgb]{1,0,0}{fpuLat}@*))(...)                      // NLC
  icache = new Cache #(icSize)(...)
  dcache = new Cache #(dcSize)(...)
  assert (icSize == dcSize) 
module Cache #(blockSize)(...) : ... 
module Core #(hasFpu,(*@\textcolor[rgb]{1,0,0}{fpuLat}@*))(...) :                              // NLC
  if(hasFpu) myFpu = new (*@\textcolor[rgb]{1,0,0}{PFPU \#(fpuLat)}@*)(...) ...                 // LC
module PFPU #(latency)(...): ...     // Add parameter to FPU 
\end{phdl}
\caption{Example of the source changes (highlighted in red) that are required to append a new leaf submodule (PFPU) that contains a new parameter.}
\label{fig:arglist-delta}
\end{figure}

\emph{Argument list parameterization} is a paradigm wherein parameters are passed-by-value through class constructor function argument lists. 
It is the most basic, lexically-scoped way of binding parameters.
Verilog and VHDL are examples of existing HDLs that solely support this paradigm for parameterizing hardware modules.
 
Figure~\ref{fig:arglist} shows code describing the hierarchical \code{Tile} generator from Figure~\ref{fig:block} using argument list parameterization.
At the root of the module hierarchy, each parameter is bound to a value which is then passed into the module hierarchy via the argument list of \code{Tile}'s constructor.
These values are then propagated through the module hierarchy via the \code{Core} and \code{Cache} modules' constructors' argument lists.

In addition to injecting values into the design, we can enforce constraints on certain parameters.
For example, in this particular \code{Tile} architecture, both the instruction and data cache must have identical cache block sizes
because they are multiplexing the same memory port to the rest of the system.
This requirement is a property of this particular \code{Tile} generator; it was unknown to the designers of the \code{Cache} module.
Furthermore, other variations on a tile generator might not enforce this particular requirement, and so we would like to expose
\code{icSize} and \code{dcSize} to the design space explorer as independent, top-level variables.
Thus, the proper place to enforce the constraint is within \code{Tile}, making reference to the parameters that must be bound together.

Figure~\ref{fig:arglist-delta} illustrates how the argument list paradigm is brittle to modifications. 
We modify \code{Core} to use a parameterized FPU, \code{PFPU \#(fpuLatency)}, which takes as a parameter the desired latency for the unit.
In order to enact this modification, we must make several changes to the extant source code:
(1) a TLC to bind parameter \code{fpuLatency} in \code{Top};
(2) a LC to instantiate the new \code{PFPU} within \code{Core};
(3) four NLCs to \code{Tile} and \code{Core}'s declaration parameter lists, as well as \code{Tile} and \code{Core}'s instantiations.
The four NLCs represent the brittleness of this particular paradigm, in that adding a parameter to a leaf module causes many non-local changes to be required in any interstitial modules.
For small designs with simple class hierarchies, the total number of NLCs might be small.
However, as we will see in Section~\ref{sec:scca}, in this paradigm the number of NLCs scales with module hierarchy size, making modifications increasingly burdensome
as the collection of generators in a particular library grows.

Further complexity arises if we consider a set of different FPU implementations, each with a unique or even partially overlapping set of parameters.
The set of parameters included in each intervening module's constructor becomes the superset of all the child modules' parameters.
Determining which parameters are actually unique and supplying default values for any which are unused in a particular design instance becomes onerous
as more and more combinations of generators are composed.

\subsection{Struct Parameterizations}

\begin{figure}
\centering
\begin{phdl}
struct TilePars {hasFpu:Bool, icSize:Int, dcSize:Int} // Structs definitions
struct CorePars {hasFpu:Bool}
module Top #()():
  tp = new TilePars(true, 64, 64)                     // Struct instantiation
  myTile = new Tile #(tp)(...)
module Tile #(params)(...):
  cp = new CorePars(params.hasFpu)                    // Struct instantiation
  myCore = new Core  #(cp)(...)
  icache = new Cache #(params.icSize)(...)
  dcache = new Cache #(params.dcSize)(...)
  assert (params.icSize < params.dcSize)
module Cache #(blockSize)(...) : ...
module Core #(params)(...):
  if(params.hasFpu) myFpu = new FPU()(...) ...
module FPU #()(...): ...
\end{phdl} 
\caption{The same example module hierarchy, but parameterized through flat structs instead of argument lists.}
\label{fig:flatstruct}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
struct TilePars {hasFpu:Bool, icSize:Int, dcSize:Int, (*@\textcolor[rgb]{1,0,0}{fpuLat:Int}@*)} // NLC
struct CorePars {hasFpu:Bool, (*@\textcolor[rgb]{1,0,0}{fpuLat:Int}@*)}                         // NLC
module Top #()():
  tp = new TilePars(true, 64, 64, (*@\textcolor[rgb]{1,0,0}{6}@*))                              // TLC
  myTile = new Tile #(tp)(...)                                    // No NLC
module Tile #(params)(...):                                       // No NLC
  cp = new CorePars(params.hasFpu, (*@\textcolor[rgb]{1,0,0}{params.fpuLat}@*))                 // NLC
  myCore = new Core  #(cp)(...)                                   // No NLC
  icache = new Cache #(params.icSize)(...)
  dcache = new Cache #(params.dcSize)(...)
  assert (params.icSize < params.dcSize) ...
module Cache #(size)(...) : ...
module Core #(params)(...) :                                     // No NLC
  if(params.hasFpu) myFpu = new (*@\textcolor[rgb]{1,0,0}{PFPU \#(params.fpuLat)}@*)(...) ...   // LC
module PFPU #(latency)(...): ...     // Add parameter to FPU 
\end{phdl} 
\caption{Example of the source changes (highlighted in red) that are required to append a new leaf submodule (PFPU) that contains a new parameter,
under the flat-struct paradigm.}
\label{fig:flatstruct-delta}
\end{figure}

If the HDL provides user-defined struct types, these can be used to encapsulate multiple parameters within individual statically-typed objects.
SystemVerilog and Bluespec SystemVerilog are two HDLs that provide this capability.
For the purposes of our taxonomy, we posit that parameterization paradigms based on structs can be organized in two particular ways.
In \emph{flat-struct parameterization}, each generator is paired with a used-defined struct type containing all parameters used by that generator and all of its children.
This approach provides only a very limited advantage over the previously discussed argument list paradigm.
In \emph{nested-struct parameterization}, instead of a generator's companion struct consisting of a flat list of parameters,
it contains its own local parameters, as well as the parameter structs for its immediate children. 
This nesting allows further abstraction of the specific fields of the child generators' structs.

Both of these schemes are still lexically scoped, but we have moved the site of the bindings into a class hierarchy of struct types,
which may be distinct from the module hierarchy itself.
This level of indirection affords us, as generator authors, some opportunities to abstract away the specifics of what parameters are needed by which children.
By reducing the number of places we have to explicitly pass individual parameters' bindings from parent module to child module, we congruently reduce
the amount of work it takes to thread new parameters through the same module class hierarchy.
Encapsulation through structs can reduce the burden of lexical scoping in the face of design modifications.

Taking this idea a step further, we can recognize that we do not have to maintain a one-to-one mapping between the class hierarchy of structs and the class hierarchy of modules.
In the most extreme case, we could put all top-level parameters into a single struct which is passed to every module in the design,
essentially recreating a flat parameter paradigm based on global constants.
Such a solution improves modifiability by eliminating all NLCs but is problematic for composability,
because it means that sub-modules within the design cannot be reused in other contexts without providing default bindings for all possible parameters from all contexts.
However, more moderate solutions that exploit differences in the struct hierarchy and module hierarchy are possible at the designers' discretion.
For simplicity, the rest of this section utilizes the simpler one-to-one mapping to illustrate the differences between the struct paradigms.

Figure~\ref{fig:flatstruct} and Figure~\ref{fig:flatstruct-delta} show how the flat-struct paradigm,
applied with a one-to-one mapping between modules and structs,
can still eliminate some non-local changes in the face of appending the PFPU module as before.
This reduction happens because the module constructor argument lists do not grow with additional parameters.
While the definitions of all the structs must be changed to account for the new parameter,
instances where a single struct instance is passed to multiple module instantiations do not need to be changed,
because the module instantiation no longer references the individual parameters as they are now encapsulated fields of the struct.
However, Figure~\ref{fig:flatstruct-delta} shows that when inserting the newly parameterized \code{PFPU},
this scheme still requires some non-local changes because every parent generators's parameter struct declaration and instantiation must be changed.
In Section~\ref{sec:scca} we will see that the flat-struct paradigm is only a constant factor less brittle than the argument list paradigm.

\begin{figure}
\centering
\begin{phdl}
struct CorePars {hasFpu:Boolean, (*@\textcolor[rgb]{1,0,0}{fpuLat:Int}@*)}                     // NLC
struct TilePars {cp:CorePars, icSize:Int, dcSize:Int}            // No NLC
module Top #()():
  cp = new CorePars(true ,(*@\textcolor[rgb]{1,0,0}{fpuLat}@*))                                // TLC
  tp = new TilePars(cp, 64, 64)                                  // No NLC
  myTile = new Tile #(tp)(...)                                   // No NLC
module Tile #(params)(...):                                      // No NLC
  myCore = new Core  #(params.cp)(...)                                                        
  icache = new Cache #(params.icSize)(...)
  dcache = new Cache #(params.dcSize)(...)
  assert (params.icSize < params.dcSize) ...
module Cache #(size)(...): ...
module Core #(params)(...):                                     // No NLC
  if(params.hasFpu) myFpu = new (*@\textcolor[rgb]{1,0,0}{PFPU \#(params.fpuLat)}@*)(...) ...   // LC
module PFPU #(latency)(...): ...     // Add parameter to FPU 
\end{phdl} 
\caption{Example of the source changes (highlighted in red) that are required to append a new leaf submodule (PFPU) that contains a new parameter,
under the nested-struct paradigm.}
\label{fig:nestedstruct-append}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
struct CorePars {hasFpu:Bool, fpuLat:Int}
struct TilePars {cp:CorePars, (*@\textcolor[rgb]{1,0,0}{cpf:CachePFPars}@*), dcSize:Int}      // NLC
struct CachePfPars {dist: Int, size:Int} // New struct for Prefetcher
module Top #()():
  (*@\textcolor[rgb]{1,0,0}{cpf = new CachePfPars(16, 64)}@*)  // Icache size now nested      // TLC
  cp = new CorePars(true, 6)
  tp = new TilePars(cp, (*@\textcolor[rgb]{1,0,0}{cpf}@*), 64)                                // NLC
  myTile = new Tile #(tp)(...)
module Tile #(params)(...):
  myCore = new Core  #(params.cp)(...)
  icache = new (*@\textcolor[rgb]{1,0,0}{CacheWithPF \#(params.cpf)(...)}@*)                   // LC
  dcache = new Cache #(params.dcSize)(...)
  assert ((*@\textcolor[rgb]{1,0,0}{params.cpf.size}@*) < params.dcSize)                      // NLC
module CacheWithPF #(params)(...):  // New module that adds prefetch functionality to cache
  myCache = new Cache #(params.size)(...)
... // Cache, Core, FPU declarations are unchanged
\end{phdl} 
\caption{Example of the source changes (highlighted in red) that are required to insert a new interstitial submodule (CacheWithPF) that contains a new parameter,
under the nested-struct paradigm.}
\label{fig:nestedstruct-insert}
\end{figure}

We can instead adopt \emph{nested-struct parameterization} to avoid the aforementioned cascading changes to all parent parameter structs' declarations and instantiations. 
Instead of a generator's companion struct consisting of a flat list of parameters, it contains only its own locally-consumed parameters as well as the parameter structs for its immediate children. 
Figure~\ref{fig:nestedstruct-append} applies this approach to the previous example of appending a parameterized FPU.
Only \code{PFPU}'s immediate parent's companion struct, \code{CorePars}, needs modification.
The fact that \code{CorePars} now has an additional parameter associated with it is now abstracted away from both \code{Tile} and \code{TilePars}.

Although the nested-structs paradigm eliminates almost all NLCs related to {\em appending} new leaf modules to the hierarchy,
it retains another disadvantage related to {\em inserting} new levels into the module hierarchy.
Figure~\ref{fig:nestedstruct-insert} provides an example of a such a scenario.
Suppose we want to add a prefetcher to our instruction cache. 
We insert module \code{CacheWithPF}, with a single parameter (\code{distance}), that instantiates our original \code{Cache} module inside of itself.
\code{CacheWithPF} wraps \code{Cache}'s output with additional logic to perform prefetching of expected instructions up to a specified \code{distance}.

The nested-struct paradigm does allow us to add \code{distance} without changing \code{Tile}'s constructor, avoiding an NLC.
Unfortunately, adding a new level of nesting in the parameter structs breaks our previously-existing assert statement in \code{Tile}. 
Because the nested structure of the parameter objects explicitly mirrors the generator hierarchy,
any changes to the nesting will break references to any child's parameters on which parent generators are enforcing constraints.
This restriction results in a whole new class of NLCs to deal with, ones that could never have arisen with the simpler argument list approach!

While both struct paradigms are acceptable for flat class hierarchies with limited possible nestings,
generators often have deep module hierarchies or interoperate with other generators from multiple libraries
(correct interoperation often necessitates the imposition of constraints in parent generators).
These lexically-scoped paradigms embrittle such designs because changes to the module hierarchy break a parent's references to its childrens' parameters. 
Note that these broken references can be located anywhere in the design
and are often not located near the LC that inserts the new module.
Overall, even nested-structs cannot guarantee a robust design, despite significantly reducing NLCs related to appending new leaf modules.
Unsatisfied with lexical scoping for deeply nested generator hierarchies, we now turn our attention to dynamic scoping solutions.

\subsection{Environment Parameterization}
\label{sec:env}

We begin by characterizing an environment-based approach to dynamic scoping of parameters.
An \emph{environment} is an associative array (i.e., map, dictionary), where each key and value pair consists of a parameter identifier and value respectively.
Environments can be inherited by an instance of a module and then passed along to its children, possibly
with modifications made to the key-value bindings.
Code within modules can gain access to certain parameter values by looking up the parameter's key in the environment.

Environments are a dynamic scoping solution because the value returned for each key is determined based on the execution of the program,
not the hierarchy of the source classes.
As alluded to earlier in this chapter, there are some tradeoffs inherent to dynamism.
Critically for composability, we do not have to pass bindings for all possible parameters through the module hierarchy explicitly.
This flexibility is a great boon for generators where some parameters are only used if certain other parameters are set a particular way,
or in cases where homogenous designs may be uniqueified to form heterogeneous ones.
If a particular instance of a design does not use a particular parameter, that parameter never has to be bound.
If a new module is added, bindings for its parameters can be supplied to the environment from any parent location in the hierarchy.
The cost we pay for this flexibility is that unbound parameters can only be detected at runtime, rather than at compile time.

A popular use of dynamic environments in the software world are those used for processes in all flavors of Unix.
Whereas shell languages in Unix systems have a first-class syntax for accessing environment values (e.g. \code{\$HOME}),
attempts to implement environments in a previously existing HDL would have to explicitly pass the environment object through the module hierarchy to query it.
Unfortunately, SystemVerilog and BluespecSV (as well as Verilog and VHDL) cannot support environments, as environments require either nested functions or HashMaps.
While the SystemVerilog language includes associative arrays (similar to HashMaps), most SystemVerilog compilers do not support it.
This type of environment could be implemented in Bluespec or SystemVerilog using tagged unions or associative arrays.
Unfortunately, neither language supports dynamically typed parameters, and thus cannot pass associative arrays as parameter objects.
Bluespec requires that all type checking be resolved prior to elaboration; since the compiler cannot guarantee that the returned value is type safe, associative arrays are not supported. 
Tagged unions, however, can be statically-type safe and used if the types of all parameters are known.
While both BluespecSV and SystemVerilog claim support for tagged unions, many SystemVerilog compilers lack support for them.

Chisel and Genesis2 leverage Scala and Perl, respectively, for metaprogramming the module hierarchy generation stage of hardware elaboration.
Because Scala and Perl support first-class functions and maps, both HDLs can easily provide the type of environment discussed here using either.
As we will see in Section~\ref{sec:impl}, Scala's support for implicit parameters makes it syntactically concise to distribute
the environment object through the module hierarchy.
Perl allows the programmer to select whether a variable is a dynamic global variable or a lexically-scoped local variable.
Rather than depend on the functionality global Perl environment, Genesis2 defines its own parameter environment framework that provides additional features.

Genesis2 supplies a parameter environment for each module and provides an API that allows users to:
define parameters,
assign them default values,
override those values from external configuration files,
force parameters to always take certain values,
and
define additional parameters at module instantiation time
\cite{shacham2011chip}.
A module can use a reference to any other module to make a reference to that module's parameters' values. 
Parameters are read-only, and queries return deep copies of mutable objects.
Because Perl is a dynamically-typed language, no type checking can be done on the return type of parameter queries.
The framework outputs XML to encapsulate the full ``configuration'', i.e., the text description of how SystemVerilog module declarations are composed.
This organization allows for iterative customization of certain parameters values within the design in accordance with the experimental design of external tools.
%Would need to explicitly rename parameters, can do this in multiple ways, including defining synonyms or referencing a parent's parameter. Adding parameters does require explicit renaming, no mechanism to reference child. Adding cde's would only benefit it, I think.

\begin{figure}
\centering
\begin{phdl}
x = {'key1' -> 1,'key2' -> 3} // Environment instantiation
y = x ++ {'key1' -> 2}        // Environment modification
print x('key1')               // Environment query, prints '1'
print y('key1')               // Environment query, prints '2'
print y('key2')               // Environment query, prints '3'
\end{phdl}
\caption{Syntax for environment instantiation, modification and querying in our pseudo-HDL.}
\label{fig:env-phdl}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
module Top #()():
  topPars = {'hasFpu'->true, 'icSize'->64, 'dcSize'->64} // Top-level bindings
  myTile = #(topPars)(...)
module Tile #(params)(...):
  myCore = new Core  #(params)(...)
  icache = Cache #(params('icSize'))(...)          // Parameter lookup
  dcache = Cache #(params('dcSize'))(...)          // Parameter lookup
  assert (params('icSize') < params('dcSize')) ... // Parameter lookups
module Cache #(size)(...) : ...
module Core  #(params)(...) :
  if(params('hasFpu') myFPU = new FPU #()(...) ... // Parameter lookup
\end{phdl} 
\caption{The same example module hierarchy, but parameterized through dynamic environments.}
\label{fig:env}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
module Top #()():
  topPars = {'hasFpu' -> true, 'icSize' -> 64, 'dcSize' -> 64, (*@\textcolor[rgb]{0,0,1}{'fpuLat' -> 6}@*), (*@\textcolor[rgb]{1,0,0}{'dist' -> 16}@*) } // TLCs
  myTile = Tile #(topPars)(...)                                  // No NLC
module Tile #(params)(...):                                      // No NLC
  myCore = Core #(params)(...)                                   // No NLC
  // The following rename from `icSize' to `size' must be handled here by icache's parent
  (*@\textcolor[rgb]{1,0,0}{icPars = params ++ \{'size' -> params(`icSize')\}}@*)                // LC for CacheWithPF
  icache = new (*@\textcolor[rgb]{1,0,0}{CacheWithPF \#(icPars)(...)}@*)                        // LC for CacheWithPF
  dcache = new Cache #(params('dcSize'))(...)
  assert (params('icSize') < params('dcSize')) ...
module CacheWithPF #(params)(...) :
  Cache #(params('size'))(...) ... // CacheWithPF queries 'size'
module Core #(params)(...) :
   if(params('hasFpu') myFPU = new (*@\textcolor[rgb]{0,0,1}{PFPU \#(params('fpuLat'))}@*)(...) // LC for PFPU
... // Cache, PFPU module declarations are unchanged
\end{phdl} 
\caption{Simultaneously appending a new submodule that contains a new parameter (highlighted in blue), while also inserting
a new interstitial module that contains a new parameter (highlighted in red). Dynamic environments eliminate NLCs.}
\label{fig:env-delta}
\end{figure}
Figure~\ref{fig:env-phdl} provides an overview of the additional syntax we introduce to our pseudo-HDL in order to allow it to support instantiation, modification, and querying of environments.
An important note is that the \code{++} operator, which adds a binding to the store, returns a new environment and does not affect the original environment.
In addition, all values in key-value pairs are lazily evaluated only when a query matches on a particular key.

Figure~\ref{fig:env} shows the code for our running example of the tile generator, modified to use the environment to supply parameters to all modules with two or more parameters.
To parameterize a child module, a parent copies its own environment and adds/overwrites any needed key-value mappings before passing it to the child.
While keys can be overridden in certain sub-modules, the overall namespace provided by the environment is flat and does not codify anything about the structure of the module hierarchy.
Figure~\ref{fig:env-delta} demonstrates the advantages of this flexiblity by applying both of the modifications from previous case study examples
(replacing the appended \code{FPU} with \code{PFPU} and inserting \code{CacheWithPF}).
Significantly, the only changes required are LCs and TLCs, with no NLCs whatsoever.
Even the cross-module assertion on cache sizes in \code{Tile} does not require modification.

Although the environment passing paradigm succeeds in removing all NLCs,
there is an additional LC required to rename the \code{icSize} parameter to \code{size}.
Why does \code{CacheWithPF} query for \code{size} instead of \code{icSize}?
The generator designer engineered it to be composable with any cache, and to avoid binding it to a particular instance.
We should not contextualize the parameter name (e.g., change \code{size} to \code{icSize}),
because in a different design the sub-module that is instantiated could be a data cache. 
Thus, an explicit renaming step is necessary to customize the parameter environment passed to \code{CacheWithPF}, telling it which top-level parameter to use
in response to any internal queries made regarding \code{size}.
We consider the source code change, required to perform the renaming by modifying the environment, an LC rather than an NLC, because it always occurs in conjunction
with the LC that instantiates the newly inserted module.
However, it is worth noting that the renaming must be performed for each unique instance of the module that takes on a different, heterogeneous value.

In general, we will often have modules that have either intentionally picked a context-free key or have simply used parameter keys that coincidentally overlap with those
used by some other imported generator.
Differentiating these conflicting keys and assigning them to the proper top-level key bindings is both the power and the burden of the dynamic environment paradigm.
For designs that do not have a large number of parameter key collisions, environment passing is a great solution as it will significantly reduce the number of NLCs. 
Unfortunately, in the prevalent case of designs that have many instances of the same child module class (e.g., a mesh of routers), the re-mapping of unique top-level parameters onto generic, re-used child parameters,
that must occur every time one of these children is instantiated, becomes onerous.
To mitigate this burden through the use of geographic information, we now turn to context-dependent environments.

\section{Context-Dependent Environments}
\label{sec:cde}

\begin{figure}
\centering
\begin{phdl}
module Example :
  env1 = {'whoami' -> (*@\textcolor[rgb]{1,0.5,0}{\textbf{\textit{site}}}@*)('coord')}                // CDE instantiation
  env2 = env1 ++ {'coord' -> 'environment 2'} // CDE modification
  print env1('whoami')                        // CDE query, prints 'Error: 'coord' is not defined'
  print env2('whoami')                        // CDE query, prints 'environment 2'
\end{phdl}
\caption{Syntax for CDE instantiation and querying in our pseudo-HDL.}
\label{fig:cde-phdl}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
module Top #()():
  constPars = { 'coefficient' -> 4 }                               // Constant function
  indexPars = { 'coefficient' -> List(4,5,6,7).at((*@\textcolor[rgb]{1,0.5,0}{\textbf{\textit{site}}}@*)('index')) } // Function on 'index'
  myHomogenousDSP   = new DSP4MultArray(constPars)     // Makes a DSP with identical coefficients
  myHeterogenousDSP = new DSP4MultArray(indexPars)     // Makes a DSP with unique coefficients
module DSP4MultArray #(params)(...):
  mult0 = new Mult #(params ++ {'index' -> 0}) m0(...) // DSP4MultArray provides context
  mult1 = new Mult #(params ++ {'index' -> 1}) m1(...)
  mult2 = new Mult #(params ++ {'index' -> 2}) m2(...)
  mult3 = new Mult #(params ++ {'index' -> 3}) m3(...) ...
module Mult #(params)(...):
  c = params('coefficient') ...                        // Mult only knows about coefficient, not index
\end{phdl}
\caption{Example of specifying geographic information using site in pseudo-HDL.}
\label{fig:site-phdl}
\end{figure}

We now describe the functionality of our novel context-dependent environments paradigm for parameterization,
and assess its robustness using the case study introduced in the previous section.
In the CDE paradigm, we again pass an associative array called an environment through a hardware module hierarchy, but the environment itself has an additional capability:
the value returned for a query on a key can depend on other parameter values at that query's origin within the design.
This feature is deceptively simple; the level of additional indirection provided in a CDE is a powerful tool for describing
parameters in terms of one another, which aids us in cascading uniquifying changes through subsets of a heterogeneous design.

While we previously demonstrated how we can use environments to provide the flexibility of dynamic binding on-demand from within a lexically-scoped module hierarchy, 
the CDEs we propose here are actually a strictly more powerful mechanism than traditional dynamic binding. 
We owe this power boost to our decoupling of ``how'' and ``when'' to compute a parameter's value,
allowing the ``how'' to be specified at binding time,
but deferring evaluation until the time at which the parameter is actually queried during elaboration.
This ``lazy'' evaluation strategy permits more parameter bindings to be in scope at
evaluation time than were available at binding time,
with the advantage that these other parameters may come from code locations not visible to the original binding site.

Mechanically, the sole additional feature of a CDE over a regular environment is a special object, called \emph{site}, that dynamically points to the originating CDE of the parameter query.
\emph{site} is available to be queried when defining the value bound to a particular identifier.
In other words, environment values bound within the environment are no longer mere literals, instead
they have been promoted to functions that take as an argument a dictionary representing the view of the world as seen from the query's point of origin.
When the environment is asked to evaluate a particular parameter identifier, the function stored for that key in the dictionary is evaluated against the dictionary itself.
Regular style environment variables are still possible in this paradigm, but now are just functions that ignore the dictionary argument and return a constant value (i.e. constant functions). 
We call these enhanced environments {\em context-dependent} because the valuations taken by their bindings depend on where the query is made.

\begin{figure}[p]
\centering
\begin{phdl}
module Top #()() :
  topPars = {'hasFpu' -> true,
             'size' -> if((*@\textcolor[rgb]{1,0.5,0}{\textbf{\textit{site}}}@*)('loc') == 'iCache') 64 else 64 }
  myTile = new Tile #(topPars)(...)
module Tile #(params)(...):
  myCore = new Core #(params)(...)
  icache = new Cache #(params ++ {'loc' -> 'iCache'})(...) // Insert geographic location
  dcache = new Cache #(params ++ {'loc' -> 'dCache'})(...) // Insert geographic location
  assert (icPar('size') < dcPar('size')) ...
module Cache #(params)(...):
  ... params('size') ... // Cache queries CDE directly
module Core #(params)(...):
  if(params('hasFpu') myFpu = new FPU()(...) ...
\end{phdl} 
\caption{The same example module hierarchy, but parameterized through context-dependent environments.}
\label{fig:cde}
\end{figure}

\begin{figure}
\centering
\begin{phdl}
module Top :
  topPars = {'hasFpu' -> true,
             (*@\textcolor[rgb]{1,0,0}{'dist' -> 16}@*),                                   // TLC
             (*@\textcolor[rgb]{0,0,1}{'fpuLat' -> 6}@*),                                  // TLC
             'size' -> if((*@\textcolor[rgb]{1,0.5,0}{\textbf{\textit{site}}}@*)('loc') == 'iCache') 64 else 64 }
  myTile = new Tile #(topPars)(...)
module Tile (params)(...):
  myCore = new Core #(params)(...)
  icache = new (*@\textcolor[rgb]{1,0,0}{CacheWithPF}@*) #(params ++ {'loc' -> 'iCache'})(...) // LC
  dcache = new Cache #(params ++ {'loc' -> 'dCache'})(...)
  assert (icPar('size') < dcPar('size')) ...
module Cache #(params)(...):
  ... params('size') ...
module CacheWithPF (params)(...):
  Cache #(params)(...)        // CacheWithPF simply passes CDE
module Core (params)(...) :
  if(params('hasFpu') myFpu = new (*@\textcolor[rgb]{0,0,1}{PFPU \#(params)}@*)(...) // Core simply passes CDE  // LC
\end{phdl} 
\caption{Simultaneously appending a new submodule that contains a new parameter (highlighted in red), while also inserting
a new interstitial module that contains a new parameter (highlighted in blue). Dynamic environments eliminate NLCs.}
\label{fig:cde-delta}
\end{figure}

Figure~\ref{fig:cde-phdl} provides a basic example of syntax and behavior for using the CDE {\em site} functionality in our pseudo-HDL.
We can see that \code{env1} is queried with the key \code{'whoami'}. 
This key is contained within \code{env1}, and its value, \code{site('coord')}, is evaluated. 
Because the original queried object is \code{env1}, \code{site} points to \code{env1} (i.e. \code{site('coord') == env1('coord')}). 
Since \code{env1} does not contain the key \code{'coord'}, this query fails.
The second query, \code{env2('whoami')}, matches because \code{env2} contains a \code{'whoami'} key. 
When \code{'whoami'}'s value is evaluated, \code{site('coord')} now points to \code{env2} (i.e. \code{site('coord') == env2('coord')}). 
Because \code{env2} contains a \code{'coord'} key, \code{site(`coord')} returns \code{'environment 2'}. 
This return value is propagated back to the original \code{env2('whoami')} callee and printed.

Now that every value in the environment can actually be a function of the bindings in the environment that is evaluating it, we can trivially
build meta-parameters that are based on formulae consisting of existing parameters, e.g. \code{\{"area"~->~site("length")~*~site("width")\}}.
This feature is a powerful capability for forming chains of parameter dependencies, in which parameters can be derived from other parameters.
Most importantly, these valuations can include reference to other parameters keys which were not known to the original generator authors,
but which are instead being defined by other generators in the hierarchy.
For example, while the original author of the \code{"area"} key may have specified only that it returns an integer,
composition with a Circle generator would override it to be bound to \code{\{"area"~->~pi~*~site("radius")~*~site("radius")\}}, whereas
composition with a Square generator would override it to be bound to the above example.
Furthermore, the actual bindings for \code{"width"}, \code{"length"}, or \code{"radius"} do not have to be supplied at the same time that
the meta-parameter \code{"area"} is bound to its value function.
As long as any interstitial generator binds those keys before the generator that uses \code{"area"} actually evaluates its query on that key,
everything will dynamically resolve to the correct value.

This \emph{site} functionality is particularly useful in the context of hardware generation because 
it allows for specialization of parameter values based on contextual or ``geographic'' information that was injected into the enviroment by any intermediate generator in the module hierarchy.
This capability is at the heart of how we uniquify certain modules in a heterogeneous design.
Exploiting this capability requires that modules in a generator library built around the CDE paradigm follow the practice of placing geographic information
as new parameters in the environments they produce for their child modules, at the point where such geographic distinctions are clear. 
For instance, a network generator will instantiate and wire together the output of many router generators.
We would like a convenient way to assign different parameter values to the routers based on their location in the topology.
To achieve this effect, we place the burden on the parent generator (network) to append each child (router)'s inherited CDE with a constant parameter, e.g. \code{\{"location"~->~(x, y)\}}.
Assuming this geographic information will be dynamically inserted into the environment by the parent,
the top-level environment is free to tune each router's behavior according to \code{"location"}
by referencing it in the site-based function \code{\{"route"~->~if(site("location")~==~(1, 2))~...~\}}.
In a homogeneous system, \code{"route"} will be bound to a constant value.
In a heterogeneous system, we will supply whatever function we please on \code{"location"},
such that the individual locations will elaborate different designs.

Figure~\ref{fig:site-phdl} provides a more detailed example of geographic specialization.
We present an array of multipliers that use a parameterized coefficient, such as might be found in a DSP engine or FIR filter.
The structure of the design is fixed: \code{DSP4MultArray} has four multipliers.
However, we want to leave the binding of particular coefficients to particular multipliers up to the top level.
If we want a homogenous set of multipliers, we can make the \code{'coefficient'} parameter a constant function.
If we want a heterogeneous set of multipliers, we can make the \code{'coefficient'} parameter a function of \code{'index'}.
The top-level parameter assignment may dispatch different values to the same query by using the geographic information known only at the origin of the query. 
In this case, \code{Mult} need know nothing about \code{'index'}.
Furthermore, we can use \code{'index'} in the top-level environment even though no generator has yet injected that key into the environment.
When we finally query \code{'coefficient'} inside of \code{Mult}, \code{site} resolves to an environment where the \code{'index'} key has since been defined (in the heterogeneous case).
This example demonstrates how components in a generator library built around CDEs can leave a hook (e.g. \code{index}) by which external modules can specialize them,
and we can how this capability is based on decoupling ``how'' and ``when'' to compute a parameter's value. 

While the context-dependent specialization provided by CDEs is a useful property for expressing heterogeneous hardware,
CDEs also improve on regular environments in terms of the robustness they provide in the face of module hierarchy modifications.
We return to the tile generator example from the previous section in Figure~\ref{fig:cde}, but now deploy the CDE \code{topPars}.
Note that, in this example, we show how we could use
\code{site} to specialize queries on \code{'size'} in order to uniquify the block size for each cache,
even though this particular tile generator requires them both to dynamically be set to have the same block size.

In Figure~\ref{fig:cde-delta} we now apply both modifications from Section~\ref{sec:tax} (i.e. replacing \code{FPU} with \code{PFPU} and inserting \code{CacheWithPF}).
Under the CDE paradigm, these modifications require only two TLCs and two LCs.
As before, using environments for dynamic binding eliminates the constructor-related NLCs and broken cross-module parameter references.
Furthermore, using \code{site} to specialize the cache line sizes means that we do not have to explicitly rename the \code{'size'} paramter, as we had to do for regular environments.
Changes to parameter bindings are handled through site-based indirections instead of in-line renamings.
This example supplies us with some intuition that the CDE paradigm is qualitatively superior to all previous paradigms.
It has fewer LCs and fewer NLCs, with an equivalent number of TLCs.
We formalize this qualitative assessment in the following section.

\section{Source Code Change Analysis}
\label{sec:scca}

\begin{figure}[p]
\centering
\epsfig{file=parameters/figures/both.pdf, width=4in}
\caption{Appending or inserting a generator to the hierarchy.
Module types are represented as shapes, and the newly inserted or appended modules are red.}
\label{fig:both}
\end{figure}

\begin{figure}
\centering
\epsfig{file=parameters/figures/CDSq2.pdf, width = 6in}
\caption{(1)-(6) are example module hierarchy modifications. 
Module types are shapes, the newly inserted or appended modules are red, and inter-module parameter references are curved arrows.}
\label{fig:attr}
\end{figure}

Section \ref{sec:tax} and Section \ref{sec:cde} used the case study of a tile generator to qualitatively contrast the efficacy of all five parameterization paradigms
at dealing with some specific modifications to the structure and hierarchy of hardware generators.
In this section we instead attempt to analytically describe the robustness of each paradigm to \textit{any possible set} of design modifications.
The results show that using CDEs \textit{always} results in a more robust design according to our metric,
but they also provide insight into when other paradigms could be equally appropriate.

As in the previous sections, we define robustness as the number of source code changes that cascade from making a modification to an existing design
consisting of a hierarchy of generators that elaborate hardware modules.
We generalize the initial modifications into one of two categories: appends or insertions.
An \emph{append} is when a new generator is incorporated as a leaf node whose instantiations do not affect the overall organization of the existing module hierarchy
(e.g. the addition of \code{PFPU} in Section \ref{sec:tax}).
In contrast, an \emph{insertion} is when a new generator is incorporated between an existing parent and child node in the hierarchy (e.g. the addition of \code{CacheWithPF}). 
Insertions change the overall structure of the module hierarchy.
See Figure~\ref{fig:both} for an illustration of this distinction.

We assume all parameters added as part of a modification each require a unique value to be bound to their identifier the top-level of the module hierarchy.
In other words, multiple copies of the same generator must be capable of being assigned different parameter values.
These unique bindings must then be brought into the scope of the place where the parameters are evaluated.
Therefore, each original modification will trigger a varying number of scoping-related source code changes,
depending on both the existing module hierarchy as well as the parameterization paradigm being employed.

In order to characterize how many source code changes of each type will be required for each class of modification under each parameterization paradigm,
we define the following attributes of a modification that introduces a new module, $M$, to the hierarchy:
\begin{itemize}%\itemsep1pt \parskip0pt \parsep0pt
\item $\theta$, the number of parameters used by $M$.
\item $\pi$, $M$'s depth in the module hierarchy.
\item $\delta$, the number of times any parent generator of $M$ is instantiated.
\item $\mu$, whether any other instances of $M$'s type exist.
\item $\rho$, the number of references to $M$'s children's parameters from any of $M$'s parents.
\end{itemize}

Figure \ref{fig:attr} depicts six examples calculating these attributes for different module hierarchies
In (1), a new module $M$ with one parameter is appended to a 3-level hierarchy with each level being of a unique type.
In (2), a module with one parameter is appended to a 3-level hierarchy where one of its ancestors is instantiated twice ($\delta = 4$), and the other two are instantiated once each.
In (3), a module with two parameters is appended to a 3-level hierarchy with a cross-module reference ($\theta = 2, \rho = 0$).
In (4), a module with two parameters is inserted into a 3-level hierarchy with a cross-module reference ($\rho = 1$).
In this case, $M$'s parent has a single reference to a parameter that is contained in $M$'s child.
In (5), a module with two parameters is appended to a 1-level hierarchy alongside a sibling of a different type than $M$ ($\mu = 0$).
In (6), a module with two parameters is appended to a 1-level hierarchy alongside a sibling that is the same type as $M$ and therefore uses the same parameter names internally ($\mu = 1$).

\begin{table}
\centering
\begin{tabular}{llll}
\toprule
Paradigm    & LC & NLC & Total Changes\\
\midrule
arg-lists      &  1              & $(\delta+\pi)*\theta$ & $1+\theta*(\delta+\pi+1)$  \\
flat-struct    &  1              & $\pi*\theta$          & $1+\theta*(\pi+1)$  \\
nested-struct  &  1              & $1+\rho$              & $2+\theta+\rho$  \\
regular-env    &  $1+\mu*\theta$ & 0                     & $1+\theta*(1+\mu)$ \\
CDE            &  $1+\mu$        & 0                     & $1+\theta+\mu$  \\
\bottomrule
\end{tabular}
\caption{Source code change models for appending or inserting a module under any parameterization paradigm.}
\label{tab:limit}
\end{table}

Given these attributes, we can calculate the number of top-level, non-local, and local changes per modification type under each paradigm.
Table \ref{tab:limit} lays out analytical models for each combination.
Top-level changes are always equal to the number of parameters added by the modification ($\theta$).
Local changes consist of instantiating the new module and local manipulations of the module's parameter bindings.
Non-local changes include any other modifications, including parent instantiations, parent declarations, modifying any parent's parameter object's instantiation/declaration,
and correcting references to parameters in parent modules.
Total changes are simply the sum of all LCs, NLCs, and TLCs.

We begin by breaking down the NLCs required under each paradigm.
The arg-list paradigm requires $(\delta+\pi)*\theta$ NLCs, because each of $\theta$ parameters must be threaded through the declarations ($\pi$) and instantiations ($\delta$) of all of its parent modules in the hierarchy.
The flat-struct paradigm reduces this overhead to $\pi*\theta$ because the $\delta$ instantiations now refer to the struct instead of the individual parameters.
The nested-struct paradigm requires only $1+\rho$ changes; a single change to the declaration of the parent module's companion struct, as well as $\rho$ changes based on how many
references to parameters in $M$'s children there are in all of $M$'s parents.
If were are appending $M$ rather than inserting it, $\rho$ will of course equal 0 because there cannot be an references to non-existent children.
The dynamically-scoped solutions require no NLCs because the bindings created by the TLC are automatically put within the scope of $M$.

As for LCs, the lexically-scoped paradigms each only require a single LC, simply instantiating the module in question.
In the case of the dynamic environments, more than one LC is needed to both instantiate the module and differentiate the parameter bindings if necessary.
In particular, we use $\mu$ to indicate whether $M$ is instantiated anywhere else in the design hierarchy.
If it is, we must now differentiate the top-level bindings that are to be used for each instance of $M$, and re-map those bindings onto the identifiers used
within $M$ as we instantiate it.
For regular environments, we introduce $\theta$ additonal LCs, because every new parameter needs to be renamed in order to disambiguate it from that of its peers.
For context-dependent environments, only a single additional LC is required, assuming the existence of a single geographical parameter whose value can be overridden for the new module.

The terms in these models help to clarify the kinds of tradeoffs we are making when we offer developers the opportunity or advice to use a particular parameterization paradigm.
For example, from the perspective of the author of a generator that will serve as the ``leaf'' node in the hierarchical graph of instantiations, there is no reason not to use argument lists.
However, as that generator becomes embedded within deeper and deeper generator hierarchies, the burden born by all the parent generators grows and grows, as captured by the $\pi$ term.
In fact, $\delta$ has an even larger potential to grow, since it is based on the number of different instantiations made anywhere in the source code,
rather than the number of parent generator constructor declarations represented by $\pi$.
The $\rho$ term governing nested-structs is highly design dependent, but is an important signifier of the work that has been done within a design to ensure composability
by making assertions about the behavior and configuration of child generators.
In other words, more robust nested designs will have higher values of $\rho$.
The $\mu$ term captures whether the module being added is resuing parameter identifiers that are being used elsewhere.
It only matters for dynamically-scoped paradigms because they must provide their own namespaces for identifiers, independent of the module hierarchy's lexcical scope.
In cases where we are heterogeneously adding an instance of a new module type, or homogenously adding an identical instantiation of an existing module type, no further work needs to be done.
Otherwise, each parameter must be uniquified as the module is instantiated.
Overall, we are making an argument that the $\delta$, $\pi$, and $\rho$ terms are the ones most likely to grow,
as well as the fact that NLCs are much more difficult to resolve than LCs because they could occur anywhere in the overall source codebase.

Despite the poor scalability of argument lists, all designs with a shallow module hierarchy are manageable with them because the number of potential modifications is itself limited. 
Designs with shallow but wide hierarchies that have expect no insertions and have few cross-module parameter references (e.g. networks) could be made robust the with nested-struct paradigm,
assuming the number of child parameters is not itself determined by a parameter.
Deep hierarchical designs with minimal module reuse (e.g. processor pipelines) must support insertions as well as appends, but the diversity of the module types involved means there will be few parameter namespace collisions. These designs will remain robust with regular environment passing.
Complicated designs with deep hierarchies, significant module reuse, and many cross-module references that must address all flavors of appends and insertions (such as our SoC generator) clearly benefit from CDEs.

This analysis is predicated on the idea that the design in question will undergo further development and be deployed in new contexts,
but that agenda is central to our agile approach to hardware development.
The qualitative benefits of using CDEs extend beyond modifiability to composability and reusability.
While CDEs have disadvantages as well, we discuss how these can be mitigated through good software engineering practices in the following sections.

\section{Implementation of CDEs in Scala}
\label{sec:impl}

We will now provide some specifics about our implementation of Context-Dependent Environments in Scala.
After an overview of functionality offered by our CDE implementation, we will discuss the Scala language features we employed to create it,
as well as provide some insights into how we integrate CDEs with Chisel-based hardware generators.

At a high level, the values returned by identifiers stored in a CDE are not constant, rather they are functions whose arguments are:
\begin{description}
\item[pname,] the name of the parameter being queried.
\item[site,] the CDE against which the query was originally made.
\item[here,] the CDE currently being defined.
\item[up,] the last CDE created before this alteration.
\end{description}
The function bound to a particular identifier can choose to ignore the \code{site}, \code{here}, and \code{up} arguments and just return a constant value,
which provides the same functionality that would be found in a regular environment.
However, the use of more sophisticated parameter valuations based on querying \code{site} and the others
allows users to create chains of parameter dependencies and easily specialize deeply nested portions of their designs.
Scala provides some language features that significantly informed our implementation of this construct,
particularly first-class functions and partial functions, as well as typed dispatch via match statements.

\subsection{Environments as Partial Functions}

\begin{figure}
\centering
\begin{scala}
val fraction: PartialFunction[Int, Int] =
  { case d: Int if d != 0 => 42 / d }

val statusHandler: Int => String = {
  case 200 => "Okay"
  case 400 => "Your Error"
  case 500 => "Our error"
}

val config: PartialFunction[String, Any] = {
  case "size" => 32
  case "name" => "divider"
  case "func" => fraction
}

\end{scala} 
\caption{Partial functions in Scala.}
\label{fig:pf}
\end{figure}

At an abstract level, environments are associative arrays (also called key-value stores, maps, or dictionaries) wherein identifiers are bound to particular values.
Scala provides a \code{map} collection as part of its standard collections library, but we chose to use an even more fundamental built-in primitive as the basis of our CDE implementation:
partial functions.
In a mathematical context, a partial function provides a function  $f: X' \rightarrow Y$ for some subset $X'$ of $X$. If $X' = X$ we would call $f$ a total function.
The critical feature of a partial function is that we can define it without knowing the exact domain $X'$.

Scala provides first class support for functions (and partial functions), meaning that they are not only declared and invoked 
but can be used in every segment of the language as just another data type. 
A first-class function may be~\cite{swartz2014learning}:
\begin{itemize}
\item created in literal form without ever having been assigned an identifier;
\item stored in a container such as a value, variable, or data structure; or
\item used as a parameter to another function or used as the return value from another function.
\end{itemize}
Figure~\ref{fig:pf} shows some examples of partial functions defined as function literals.

The applicability to maps is obvious, and in fact Scala provides built-in functionality for converting between map data structures and first class partial function types.
Our CDEs are built on top of this capability by composing hierarchies of partial functions that map from an identifier
to a parameter value (or Scala object created using multiple parameters).
Our framework is permissive about what Scala objects can be used as an identifier, accepting \code{Any} Scala type.
We can than use the pattern matching tools built in to Scala to match certain parameter names and extract additional information that may be stored in them.
Figure~\ref{fig:paramspf} provides some examples of making use of different types of identifiers and alterations.

\begin{figure}
\centering
\begin{scala}
val p1 = Parameters.empty.alter(Map("a" -> 1))
val a = p1[Int]("a")

val p2 = p1.alterPartial({"b" => 2})
val b = p2[Int]("b")

case class Location(x: Int, y: Int) extends Field[String]

val p3 = p2.alterPartial({
  case Location(x, 1) => "y is 1, x is " + x
  case Location(1, y) => "x is 1, y is " + y
})

val s = p3(Location(0,1))
\end{scala} 
\caption{Using partial functions and maps to bind parameter values.}
\label{fig:paramspf}
\end{figure}

We provide the \code{Field} wrapper class to improve the syntax for looking up a particular identifier, 
allowing us to elide declaring the expected return type on each lookup of the identifier.
By giving the identifier its own Scala class, we also can leverage the Scala type system to check that indentifiers from different projects to do not conflict.

The values returned by our framework can also be of \code{Any} Scala type.
The framework uses the type specified in the \code{Field} definition 
or the one provided by the user at the query site
to dynamically cast the value obtained from the environment to the intended type.
This cast can fail at runtime if the wrong type of object is provided, an inherent weakness of our dynamic scoping approach.

Partial functions can naturally be composed with one another. If an identifier fails to match
within a certain context, we can catch the \code{MatchError} thrown and then go on to search
in the remaining ones.
We exploit this functionality to create hierarchies of environments,
where modifying a parent creates a child with new bindings that can override the parent's bindings,
while in the absence of new bindings fall back on the parent's bindings.

\subsection{site, here, and up}

\begin{figure}
\centering
\begin{scala}
val p1 = Parameters.empty

val p2 = p1.alter(
  (key, site, here, up) => key match { 
    case "width" => 64
    case "double" => here("width") * 2  // here reference
    case "hetero" => site("loc") match {
      case Location(x, 1) => "In core location #" + x
      case Location(y, 2) => "In uncore location #" + y
    }
  }
) 

val core1 = Module(new Core(p2.alter("loc" -> Location(1,1))))
val core2 = Module(new Core(p2.alter("loc" -> Location(2,1))))
val uncore = Module(new Uncore(p2.alter("loc" -> Location(1,2))))

\end{scala} 
\caption{Using \code{site}, \code{here} and  \code{up} for context-dependent parameterization.}
\label{fig:site}
\end{figure}

As discussed in the previous section, the fundamental additional feature of a CDE over a regular environment is a special object,
called \emph{site}, that dynamically points to the originating CDE of the parameter query.
\emph{site} is available to be queried when defining the value bound to a particular identifier.
In other words, environment values bound within the environment are no longer mere constant literals, instead
they have been promoted to functions which take as an argument a dictionary representing the view of the world as seen from the query's point of origin.
When the environment is asked to evaluate a particular parameter identifier, the function stored for that key in the dictionary is evaluated against the dictionary itself.
We call parameters that use the \emph{site} functionality {\em context-dependent} because the valuations taken by their bindings depend on where the query is made.
We call \emph{site} itself a \emph{view} of the environment.

In addition to the view from \code{site}, we also provide users attempting to alter their environments with the views called \code{here} and \code{up}.
\code{site} gives the user access to parameter valuations based on the value the have been modified to take at the call site.
\code{here} gives the user access to parameter valuations that are being defined within the very same alteration statement.
\code{up} gives the user access to parameter valuations that were available in the previous, un-altered version of the environment.
Figure~\ref{fig:site} shows examples of how \code{site}, \code{here}, and \code{up} can be used to evaluate parameters based on their particular view of the environment.

\subsection{Constraints}

\begin{figure}
\centering
\begin{scala}
case object NClients extends Field[Int]

class MyScalableNetwork extends Module {
  params.constrain( ex => ex(NClients) >  0 ) 
  ...
} 

class MyTinyNetwork extends Module {
  params.constrain( ex => ex(NClients) > 0 && ex(NClients) <= 4 )
  ...
} 

class MyPairsNetwork extends Module {
  params.constrain( ex => ex(NClients) > 0 ) 
  params.constrain( ex => ex(NClients) <= 32 )
  params.constrain( ex(NClients)\%2 === 0 )
  ...
} 
\end{scala} 
\caption{Constraining parameter values. }
\label{fig:constraints}
\end{figure}

As the author of a hardware generator library, it is important to expose to external users (e.g., SoC architects)
not only the free parameters of the design, but also any constraints that must be placed on
the values bound to those parameters. 
While preventing illegal parameters bindings from producing incorrect designs can be done with elaboration-time assertions
in the generator source code, we feel a better strategy is to give SoC authors enough information
so as to avoid even attempting to generate bad designs in the first place.

We provide a constraint expressions library that operates on \code{Fields}.
Users can deploy this library to create simple expressions that describe relationships between parameters.
Figure~\ref{fig:constraints} shows some examples of constraint expressions.
Within any \code{Module} or \code{Bundle} component of our library, we can constrain the values of arbitrary fields using these expressions,
and register them using the \code{constrain} function.
We support a set of expressions compatible with many constraint solving tools %($===, +, -, *, \%, <, >, <=, >=, \&\&, ||, ^$), 
as well a range checking bound.

In addition to using constraints as runtime assertions while elaborating a particular hardware design instance,
we also experimented with extracting them from a design during elaboration and serializing them
to an external format compatible with a constraint solving tool.
When using the Chisel compiler in this mode, at least one safe set of parameter bindings must be known
(we discuss a mechanism for encoding safe default values in the next subsection).
As we elaborate a design instance using these default parameters, we record all the constraints
registered by the compiler.
This set of constraints can then be fed to an external tool capable of enumerating all legal parameter bindings.
This enumerated design space can then be explored in order to find the optimal design point for a particular workload or metric.

\subsection{External Interfaces}

\begin{figure}
\centering
\begin{scala}
class DefaultConfig extends ChiselConfig { 
  val topDefinitions:World.TopDefs = { 
    (pname,site,here) => pname match { 
      case NTiles => Knob('NTILES') 
      ...
    } 
  } 
  override val topConstraints:List[ViewSym=>Ex[Boolean]] = List(
    ex => ex(NTiles) >= 1 && ex(NTiles) <= 8 && (ex(NTiles)\%2 === 0 || ex(NTiles) === 1)
  )
  override val knobValues:Any=>Any = { 
    case 'NTILES' => 1 // generator parameter assignment 
  } 
} 

class With2TilesConfig extends DefaultConfig {
  override val knobValues:Any=>Any = { 
    case 'NTILES' => 2
  } 
} 

\end{scala} 
\caption{ChiselConfigs and Knobs.}
\label{fig:configs}
\end{figure}

We provide two further abstractions as part of our Scala CDE library, both focused on interactions with external tools.

\code{Knobs} are hooks intended for use by design space explorers using CDEs to inject parameters into a design.
They provide another level of name binding indirection available witin the top-level definitions (\code{TopDefs})
of a \code{Parameter} environment.
They essentially serve as meta-parameters to which multiple other parameters' names can be bound, depending on the
use case of the exploration process.
Knobs values are automatically flagged to be dumped to external files when a particular design instance is created using them.

\code{ChiselConfigs} are representations of complete or partial parameter bindings, associated with a particular name and expressed using Scala source code.
\code{ChiselConfigs} consist of the three primary components potentially needed to elaborate a design instance based on CDEs:
top-level \code{Parameter} definitions, \code{Knob} value bindings, and top-level \code{Constraints}.
We chose to express configurations via Scala source code rather than an external serialization format for economy of design.
Given the name of a \code{ChiselConfig} sub-class, we can instantiate it using Scala's reflection capabilities and feed the \code{Parameters} thereby generated to Chisel.
\code{ChiselConfigs} can extend one another through Scala's multiple inheiritance as well as be composed by name dynamically.
Figure \ref{fig:configs} provides a simple example of \code{ChiselConfig} definition and inheiritance.




\section{Parameterization Best Practices In Chisel}

The goal of this section is to distill some of the learned wisdom about effective software engineering strategies
for deploying CDEs in a Chisel-based hardware generator.
Beyond which parameterization paradigm to use,
there are additionally a wide variety of design decisions that aid the process of injecting parameters into a design.
In particular, Scala provides several built-in features that we exploit, which are not innately coupled to our choice to use
CDEs for paramterization, but do complement it.
The following subsections attempt to capture some of the tradeoffs we have explored while taping out chips using our SoC generator.

\subsection{Scala's Implicit Parameter Lists}

\begin{figure}
\centering
\begin{scala}
class A(implicit p: Parameters ) extends Module {
  val w = p[Int]("width")
}

class B(implicit p: Parameters) extends Module {
  val a16 = Module(new A) // A's constructor's implicit parameter resolves to p
  val a32 = Module(new A(p.alterPartial({"width" => 32})))
}

val b = Module(new B(Parameters.empty.alter(Map("width" -> 16}))))
\end{scala} 
\caption{Using Scala's implicit parameters to pass Parameter instances to Modules when no fields are overridden.}
\label{fig:implicit}
\end{figure}

Implicit parameters are form of lexical scoping that offer some of the perks of dynamic scoping in a limited (but safe) context.
They are another built-in feature of the Scala language.
When a method or constructor declares one of its parameters as \code{implicit}, 
users of that method can decide whether or not to supply a value for that parameter.
In cases where no explicit value is supplied, the compiler automatically searches the context
of the method call for a matching ``implicit'' value.
Resolution rules for implicit parameters guarantee that only a single matching value will be allowed to be bound by the compiler.
The salient feature of the \code{implicit} resolution rules is that they are based on only
a single value of a matching type being marked with the \code{implicit} keyword in lexical scope.

Implicit parameters simplify Scala APIs by eliding parameters with which standard users do not need to concern themselves.
In our case, we have found them to be particularly useful for passing our \code{Parameters} objects through a hierarchy of Modules and Bundles.
In cases where none of the Parameter fields are being altered (which is the common case),
users do not have to explicitly pass the \code{Parameter} instance into the Module of Bundle's constructor.
Figure~\ref{fig:implicit} shows examples of how implicit parameters are expressed in Scala and how we use them to make \code{Parameters}
available throughout a hardware Module hierarchy.
  
\subsection{Scala Traits and Mix-ins}

\begin{figure}
\centering
\begin{scala}
trait HasTileLinkParameters {
  val p: Parameters // Abstract member
  val co = p[CoherencePolicy]("TLCoherencePolicy") // Parameters bound to local vals
  val nM = p[Int]("TLNManagers")
  val nC = p[Int]("TLNClients")
  val dataBits = p[Int]("TLDataBits")
  val dataBeats = p[Int]("TLDataBeats")
  val dataBitsPerBeat = dataBits / dataBeats // Derived parameter
}

trait HasCacheParameters {
  val p: Parameters // Abstract member
  val nSets = p[Int]("NSets")
  val nWays = p[Int]("NWays")
}

class MyBundle(implicit val p: Parameters) extends Bundle // Concrete type
    with HasTileLinkParameters {                          // supplies p for trait
  val data = UInt(INPUT, width = dataBits) // Use a val from the trait
}

class MyCache(implicit val p: Paramaeters) extends Module
    with HasCacheParameters
    with HasTileLinkParameters { // Multiple inheritance
  val io = new MyBundle // Implicit parameter passed here
  val managers = for (i <- 0 until nM) yield { ... }
  val sets = for (i <- 0 until nSets) yield { ... }
}
\end{scala} 
\caption{Using traits to factor out and mix in parameter bindings.}
\label{fig:mixin}
\end{figure}

Scala supports multiple inheritance, wherein member definitions of multiple classes can be reused in the definition of a new class.
This multiplicity is accomplished without inheritance ambiguity by way of {\em mixins},
which are classes that contains methods for use by other classes without having to be the parent class of those other classes.
Specfically, Scala allows users to define mixin {\em traits}
that represent a distinct feature or aspect orthogonal to the responsibility of a concrete type.
A trait cannot itself be instantiated, instead the trait's functionality is mixed-in when defining or using a class.
Since traits are innately abstract, they can contain abstract methods and members that are to be filled in by the concrete class.

We have found it productive to use traits to encapsulate the process of extracting parameter values from CDEs and binding them to local variable names.
Parameter lookups need only occur once per class instantiation, instead of every time a particular parameter is used.
Code reuse is improved across many classes that make use of the same parameters, such as all the Bundles in
a multi-channel protocol specification.
Figure~\ref{fig:mixin} shows examples of how we mix-in traits containing parameter bindings to Module and Bundle sub-classes.

\subsection{Case Classes versus Fields}

\begin{figure}
\centering
\begin{scala}
// Using Fields

class TLCoherencePolicy extends Field[CoherencePolicy]
class TLNManagers extends Field[Int]
class TLNClients extends Field[Int]
class TLDataBits extends Field[Int]
class TLDataBeats extends Field[Int]

trait HasTileLinkParametersFromFields {
  val p: Parameters
  val co = p(TLCoherencePolicy)
  val nM = p(TLNManagers)
  val nC = p(TLNClients)
  val dataBits = p(TLDataBits)
  val dataBeats = p(TLDataBeats)
  val writeMaskBits: Int = ((dataBits / dataBeats) - 1) / 8 + 1
  val dataBitsPerBeat: Int = dataBits / dataBeats // Derived parameter
}

// Using case classes

case class TileLinkParameters(
    coherencePolicy: CoherencePolicy,
    nManagers: Int,
    nClients: Int,
    dataBits: Int,
    dataBeats: Int = 4,
    overrideDataBitsPerBeat: Option[Int] = None
    ) {
  val writeMaskBits: Int  = ((dataBits / dataBeats) - 1) / 8 + 1
  val dataBitsPerBeat: Int = overrideDataBitsPerBeat.getOrElse(dataBits / dataBeats)
}

class TLKey extends Field[TileLinkParameters]

trait HasTileLinkParametersFromStructs {
  val p: Parameters
  val tl = p(TLKey)
  val co = tl.coherencePolicy
  val nM = tl.nManagers
  val nC = tl.nClients
  val dataBits = tl.dataBits
  val dataBeats = tl.DataBeats
  val writeMaskBits = tl.writeMaskBits
  val dataBitsPerBeat = tl.dataBitsPerBeat
}
  
\end{scala} 
\caption{
Two alternative approaches to representing sub-fields of interrelated parameters.
In the first example, we use \code{Fields} representing individual parameters, and relate them inside of a \code{trait}.
In the second example, we use a \code{case class} that wholly encapsulates the parameters and their relationships.
}
\label{fig:fields}
\end{figure}

Another parameterization design decision that is orthogonal to the choice of paradigm is
the granularity with which individual parameters are exposed to the rest of the design.
Figure~\ref{fig:fields} shows two alternative approaches generator authors can take to exposing
the parameters used by their generator to external clients.
Each have pros and cons, and designers using our tools have employed each in different instances.

In the first approach, every independent parameter is represented by an individual \code{Field} definition.
Dependent parameters are then defined in traits after the parameters have been bound to local variables.
This approach plays nicely with our \code{Constraints} framework,
which relies on individual parameters being referenced in the expressions built up to describe a constraint.
However, it requires users to mix-in the traits to gain access to their members that are storing parameter values.
It also imposes an additional burden when we work with context-dependent parameters, as we will discuss
in the next subsection.

In the second approach, every independent parameter is made a member of a case class.
Scala case classes export their constructor parameters,
provide a succinct syntax for copy constructors,
and provide a recursive decomposition mechanism via pattern matching.
Dependent parameters are defined within the class itself.
This approach is not as compatible with our \code{Constraints} framework, which at this time
does not support constraints defined on individual class members.
However, it provides all dependent parameters inherently, requiring no mixins.
It also provides a convenient syntax for working with context-dependent parameters.

\subsection{Geography and Heterogeneity}

\begin{figure}
\centering
\begin{scala}
case object CacheName extends Field[String] // New geographical fields
case object TLId extends Field[String]

class DefaultConfig extends Config(
  topDefinitions = { (pname,site,here) =>
    pname match {
      case "NSets" => 128 // A context-independent (constant) lookup
      case "NWays" => if(site(CacheName) == "L1I") 2 else 4 // A context-dependent lookup
      case TLKey => if(site(TLId) == "L2ToMC") {            // and another
          TileLinkParameters(
            coherencePolicy = new MEICoherence(new NullRepresentation(site(NBanksPerMemoryChannel))),
            nManagers = 1,
            nClients = site(NBanksPerMemoryChannel),
            dataBits = site(CacheBlockBytes)*8)
        } else {
          TileLinkParameters(
            coherencePolicy = new MEICoherence(new NullRepresentation(site(NBanksPerMemoryChannel))),
            nManagers = 1,
            nClients = site(NBanksPerMemoryChannel),
            dataBits = site(MemoryInterfaceBytes)*8)
        }
      //...
    }
  }
)

// Inject geography into context
val l2toMCNetwork = Module(new TLNetwork()(params.alter({TLId => "L2toMC"})))

// A different location
val outerNetwork = Module(new TLNetwork()(params.alter({TLId => "Outermost"})))

// Can be multiply located
val icache = Module(new ICache()(params.alter({CacheName => "L1I"; TLId => "L2toMC"})))

\end{scala} 
\caption{Using CDEs to express geographical heterogeneity.}
\label{fig:geo}
\end{figure}

Figure~\ref{fig:geo} shows examples of how geographical information can be embedded in a CDE
and exploited by making use of the \code{site} functionality.
For each parameter that varies heterogeneously across the design, we use \code{site}
to reference another parameter that abstractly describes the ``location'' of that parameter within the design.
Parameters that vary together are keyed off of the same geographic parameter.
It is important to note that the original generator library does not need to know anything about
this geographical parameter:
it can be introduced by external users and injected into the design at the top-level or anywhere in between.
\code{site} is what allows us to decouple the definition of the parameters bindings from the run-time evaluation of their values,
which vary based on ``where'' they are queried.

\subsection{The FindBy Pattern}

\begin{figure}
\centering
\begin{scala}
case object CacheName extends Field[String]
case object TLId extends Field[String]
case class TLKey(id: String) extends Field[TileLinkParameters]

class DefaultConfig extends Config(
  topDefinitions = { (pname,site,here) =>
    type PF = PartialFunction[Any,Any]
    def findBy(sname:Any):Any = here[PF](site[Any](sname))(pname)
    pname match {
      case "NSets" => findBy(CacheName) // Pivot to lookup by cache name
      case "NWays" => findBy(CacheName) // Likewise
      case "L1I" => { // Icache location
        case "NSets" => 128
        case "NWays" => 2
      }:PF
      case "L1D" => { // Dcache location
        case "NSets" => 128
        case "NWays" => 4
      }:PF
      case TLKey("L2toMC") => // First
        TileLinkParameters(
          coherencePolicy = new MEICoherence(new NullRepresentation(site(NBanksPerMemoryChannel))),
          nManagers = 1,
          nClients = site(NBanksPerMemoryChannel),
          dataBits = site(CacheBlockBytes)*8)
      case TLKey("Outermost") => site(TLKey("L2toMC")).copy(dataBeats = site(MemoryDataBeats))
      //...
    }
  }
)
\end{scala} 
\caption{Using a transformation to collate related parameters in a Config based on geography.}
\label{fig:findby}
\end{figure}

While allowing each parameter to vary independently based on geographical parameters is a powerful capability,
in practice many sets of parameters vary together because they are controlling the same generator.
We have found that users are often discontent with varying each of these correlated parameters independently.
When many locations are possible for each parameter, the replicated code to select among them can
take up a significant fraction of the Config description. 
Figure~\ref{fig:findby} shows examples of other strategies for managing correlated parameters.

The first method we introduce we term the \code{findBy} pattern. We add a utility function that
makes use of both \code{site} and \code{here} in order to pivot the parameter lookup such that we first lookup
the geographic key and then within that namespace lookup the original parameter query.
This pivot has the effect of allowing us to organize parameter bindings that change in the same way
so as to be sorted by geographical location.

The second method performs a similar transformation, but builds on the earlier design decision
to use case classes to store related parameters rather than individual fields.
This pattern is concise and allows us to make use of the copy constructor syntax built into case classes, because we
can reference other geographic keys directly.
In cases where we do not need to define constraints on individual parameters, we find we prefer this syntax.
However, this is more of a stylistic choice than a functional one, as the two approaches
are functionally equivalent.

We will return to some of these examples in later chapters after we define further properties of TileLink networks and CoherencePolicies.

\section{Discussion and Future Work}
\label{sec:con}

Unlike high-level synthesis tools that transform abstract descriptions of a computation into gates,
hardware generators are parameterized, programmatic descriptions of how to elaborate a templated RTL module hierarchy.
Because parameters are so essential to generators, we have devoted significant effort to
developing a parameterization paradigm that supports composing them.
As we look forward, we envision Chisel serving as the basis on which more abstract and high-level tools will be layered.
We contend that parameterization will be just as important for such tools.
Even though some of the details of the implementation may become hidden,
we will need to provide direction for how the high-level computations should be mapped
onto hardware structures.
Furthermore, the space of possible implementations for a HLS description can be quite large,
so expressing those tradeoffs in a way that is compatible with design space exploration is important.

While I will not discuss it further as part of this thesis, we have prototyped some initial implementations
of hooking up our \code{Parameters} and \code{Constraint} abstractions to a design space exploration tool, called Jackhammer.
Given a set of free top-level parameters and a set of constraints placed upon them, Jackhammer can create a design of experiments and
execute that design against a cloud-based service for design point evaluation.
Further work is required to automate the exploration process, and close the loop between feedback from one iteration of examining a
set of design instances and selecting points for further exploration.

The biggest downside to relying on a dynamically-scoped solution for parameterization is that there
are a class of errors that would be compile-time errors in a lexically-scoped system that are
run-time errors in a dynamically-scoped one.
These errors include things such as:
parameters never being bound to a value, function, or \code{Knob};
parameters being bound to return a type that does not match that expected by their query site;
or infinite recursion of the the CDE implementation due to loops in the \code{site} call graph.
While we have attempted to provide sensible error messages for some of these cases,
it is difficult to wholly absolve ourselves of introducing the possibility of run-time failures.
In the future, it might be possible to use Scala's support for macros to do a better job of eliding the need for runtime type casts
in cases where the top-level configuration is itself specified as Scala source code.
Overall, we feel that the power of dynamic scoping for modification of parameters in deeply nested hierarchies,
such as those seen in our RocketChip generator, is worth the cost.

\section{Conclusion}
\label{sec:con}

We have presented a taxonomy of existing parameterization paradigms in HDLs and demonstrated that our 
context-dependent environments paradigm is provably more robust in the face of modification to any given design's module hierarchy. 
We have also provided case studies of how CDEs are particularly appropriate for hardware generators,
and offered insights into how best to deploy them within a new HDL embedded in Scala.
In the following chapters, we will move on to the specifics of how to express cache coherence protocols with hardware generators,
and build on the CDE framework to effectively parameterize both the protocols themselves and the hardware modules that implement them.
